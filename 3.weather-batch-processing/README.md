# ğŸŒ¤ï¸ Project 3/50: Weather Data Pipeline on GCP

This project uses a Cloud Function and Cloud Scheduler to fetch live weather data every 15 minutes and insert it into BigQuery.

---

## ğŸ› ï¸ Tools Used
- **Google Cloud Functions** (Python)
- **Cloud Scheduler** (cron-like scheduling)
- **BigQuery** (data storage)
- **Open-Meteo API** (weather source)

---

## ğŸ“ Project Structure

```
weather-pipeline/
â”œâ”€â”€ fetch_weather.py           # Cloud Function to fetch and write data
â”œâ”€â”€ requirements.txt           # Python packages
â”œâ”€â”€ deploy.sh                  # Deploys function + scheduler
â”œâ”€â”€ cleanup.sh                 # Deletes all GCP resources
â””â”€â”€ README.md
```

---

## ğŸš€ How It Works

1. `Cloud Scheduler` triggers every 15 minutes.
2. `Cloud Function` fetches weather data via API.
3. Parses and writes data to `BigQuery` table.
4. You get historical weather snapshots.

---

## âœ… Setup

1. Edit `deploy.sh` and replace:
   - `your-project-id`
   - `your_dataset`

2. Run:
```bash
chmod +x deploy.sh
./deploy.sh
```

---

## ğŸ“¦ Example Output in BigQuery

| temperature | windspeed | recorded_at         | fetched_at           |
|-------------|-----------|---------------------|----------------------|
| 28.5        | 10.8      | 2024-06-21T10:00:00Z | 2024-06-21T10:00:10Z |

---

## ğŸ§¹ Cleanup

To delete all deployed resources:

```bash
chmod +x cleanup.sh
./cleanup.sh
```

---

## ğŸ“Œ Notes

- Uses Open-Meteo API (no API key required)
- Timestamp columns use UTC
- Scheduler time zone is set to Asia/Kolkata

---

Happy building â˜ï¸